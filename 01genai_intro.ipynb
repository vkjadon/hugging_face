{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjr9yMMcsiefq6ZdkAU+kw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkjadon/hugging_face/blob/main/01genai_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That is a fantastic choice! Google Colab is actually the preferred environment for many developers because it comes with Python pre-installed and allows you to hide your API keys securely using \"Secrets.\"\n",
        "\n",
        "Since we are in Colab, let's adjust your Step 1 setup to make it \"Pro\" level.\n",
        "\n",
        "Step 1 (Updated for Colab): Secure Setup\n",
        "In Colab, you should never paste your API key directly into a code cell. If you share the notebook, others will see your key! Instead, do this:\n",
        "\n",
        "Store the Key: On the left sidebar of Colab, click the key icon (Secrets).\n",
        "\n",
        "Add New Secret: Name it GEMINI_API_KEY and paste your key into the Value field.\n",
        "\n",
        "Enable Access: Toggle the \"Notebook access\" switch to on."
      ],
      "metadata": {
        "id": "htPY6-53vjci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nGPQSd94kY0I"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "Y3XINDx6vrTX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    print(m.name)"
      ],
      "metadata": {
        "id": "_NxGf4gQtp7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=\"gemini-2.5-flash-lite\""
      ],
      "metadata": {
        "id": "G_AuBVlqc7ju"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents=\"Explain why Google Colab is great for AI in 1 sentence.\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ39jNshOlfI",
        "outputId": "5650f1f6-a5d9-436b-e632-4ff4b4c36757"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Colab is great for AI because it provides free access to powerful GPUs and TPUs, along with pre-installed libraries, making AI development accessible and efficient without needing local hardware.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use a dedicated types module to configure the AI's behavior, which is the best practice for structured, reliable code."
      ],
      "metadata": {
        "id": "sauC1CN5TdSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents=\"How does AI work?\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(thinking_budget=0) # Disables thinking\n",
        "    ),\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "eQjSWQ2UTInS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=model,\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"You are a cat. Your name is Neko.\"),\n",
        "    contents=\"Hello there\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3AJuq3bT04H",
        "outputId": "c7baa701-fb46-4f0c-d32a-6191deda2936"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*Purrrr...* Oh, hello there, human! You have my attention. What brings you to my humble abode? Are you perhaps here to admire my magnificent fur? Or maybe you have a treat? *Wiggles tail hopefully.*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generateContent method is your primary text/multimodal call, but its true power comes from passing a configuration object. We will use types.GenerateContentConfig to control two key parameters: temperature and thinking_level. Temperature Controls randomness/creativity. Lower values (e.g., 0.0) are for tasks requiring accuracy (e.g., summarization, code generation). Higher values (e.g., 1.0) are for creative tasks (e.g., poetry, storytelling). The maximum value is 2.0.\n",
        "\n",
        "Thinking Level Allows you to adjust the depth of the model's internal reasoning. Use \"high\" for complex agentic tasks (e.g., business strategy) and \"low\" for latency-sensitive, simple tasks (e.g., data extraction). \"low\", \"medium\", \"high\". Allowed in Gemini 3 Pro.\n"
      ],
      "metadata": {
        "id": "tE-qXOxXbVdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "creative_config = types.GenerateContentConfig(\n",
        "    temperature=1.0,           # High creativity\n",
        "    max_output_tokens=512      # A useful constraint for output length\n",
        ")"
      ],
      "metadata": {
        "id": "Zkb6vGi4cRTg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents=\"Write a 12-line poem about a rocket launch, focusing on the pilot's final thoughts.\",\n",
        "    config=creative_config\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "sTBSi8m7bVIs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}